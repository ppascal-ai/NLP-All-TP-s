{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "054304c73b6e41a1973f8ef96fb80777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba14e70104ec4e71bef6d29d4baa9e25",
              "IPY_MODEL_e5c3bf5de78b4fddb06d4b874680325a",
              "IPY_MODEL_ea027ac70c15425d81eb6ee16bec3478"
            ],
            "layout": "IPY_MODEL_aec983df602048f9a025372a5f740c86"
          }
        },
        "ba14e70104ec4e71bef6d29d4baa9e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62ee41d2c2494605aedb5793657d35de",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b659f6fb7904bc4a84f157ec04f2ef0",
            "value": "Map:‚Äá100%"
          }
        },
        "e5c3bf5de78b4fddb06d4b874680325a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff217fca1f746c7b71ac04012ad58ea",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e84464c171154ce4b09c59fa01f46b83",
            "value": 500
          }
        },
        "ea027ac70c15425d81eb6ee16bec3478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37f2bb8bb5dc4c7d8a43b087b4649549",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b5f338cfd0434eddb8b11b0c4cc2fe91",
            "value": "‚Äá500/500‚Äá[00:00&lt;00:00,‚Äá1413.17‚Äáexamples/s]"
          }
        },
        "aec983df602048f9a025372a5f740c86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62ee41d2c2494605aedb5793657d35de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b659f6fb7904bc4a84f157ec04f2ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ff217fca1f746c7b71ac04012ad58ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e84464c171154ce4b09c59fa01f46b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37f2bb8bb5dc4c7d8a43b087b4649549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f338cfd0434eddb8b11b0c4cc2fe91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "edILcnaROYLK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "hf_token = userdata.get(\"TOKEN_All_acces\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    token=hf_token,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map={\"\": device},\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjJr-0joPZCI",
        "outputId": "e36b2a9d-b397-4c39-b783-ebfc6710cac3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n‚öôÔ∏è Configuring LoRA...\")\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ],
      "metadata": {
        "id": "bCP1Z6eNV6Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e504f6-d573-4fbf-e558-dc40334f8835"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚öôÔ∏è Configuring LoRA...\n",
            "trainable params: 11,272,192 || all params: 1,247,086,592 || trainable%: 0.9039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "def format_prompt(example):\n",
        "    \"\"\"Format wiki_medical_terms into a Llama 3 QA-style prompt.\"\"\"\n",
        "    term = example.get(\"page_title\", \"\").strip()\n",
        "    text = example.get(\"page_text\", \"\").strip()\n",
        "\n",
        "    # On v√©rifie qu'on a du contenu\n",
        "    if not term or not text:\n",
        "        return None\n",
        "\n",
        "    # On prend une d√©finition courte = 1 ou 2 phrases max\n",
        "    sentences = text.split(\". \")\n",
        "    if len(sentences) == 1:\n",
        "        definition = sentences[0]\n",
        "    else:\n",
        "        definition = \". \".join(sentences[:2])\n",
        "\n",
        "    definition = definition.strip()\n",
        "    if not definition.endswith(\".\"):\n",
        "        definition += \".\"\n",
        "\n",
        "    question = f\"What is {term}?\"\n",
        "    answer = definition\n",
        "\n",
        "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "The answer is: {answer}<|eot_id|>\"\"\"\n",
        "\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "print(\"\\nüìö Loading wiki_medical_terms dataset...\")\n",
        "raw_ds = load_dataset(\"gamino/wiki_medical_terms\")\n",
        "raw_train = raw_ds[\"train\"]\n",
        "\n",
        "print(\"üßπ Formatting dataset...\")\n",
        "formatted_examples = []\n",
        "for ex in raw_train:\n",
        "    out = format_prompt(ex)\n",
        "    if out is not None:\n",
        "        formatted_examples.append(out)\n",
        "\n",
        "# On garde 500 exemples pour rester dans l‚Äôesprit du lab\n",
        "formatted_examples = formatted_examples[:500]\n",
        "train_dataset = Dataset.from_list(formatted_examples)\n",
        "\n",
        "print(f\"‚úÖ Training on {len(train_dataset)} examples\")\n"
      ],
      "metadata": {
        "id": "IXwWdCcOYjJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58cdbf06-0cf7-469e-bf94-855e1f98b37d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìö Loading wiki_medical_terms dataset...\n",
            "üßπ Formatting dataset...\n",
            "‚úÖ Training on 500 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "print(\"\\nüìä Loading dataset...\")\n",
        "raw = load_dataset(\"gamino/wiki_medical_terms\")\n",
        "raw_train = raw[\"train\"]   # use the train split\n",
        "\n",
        "print(\"üîÑ Formatting dataset...\")\n",
        "\n",
        "formatted_examples = []\n",
        "for ex in raw_train:\n",
        "    out = format_prompt(ex)   # our function from the slide\n",
        "    if out is not None:\n",
        "        formatted_examples.append(out)\n",
        "\n",
        "# keep only 500 examples\n",
        "formatted_examples = formatted_examples[:500]\n",
        "\n",
        "# turn back into a Hugging Face Dataset\n",
        "train_dataset = Dataset.from_list(formatted_examples)\n",
        "\n",
        "print(f\"‚úÖ Training on {len(train_dataset)} examples\")\n",
        "print(train_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhhMRYsRakvK",
        "outputId": "bdfdd826-19fd-454b-ab1b-e78986c15b56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Loading dataset...\n",
            "üîÑ Formatting dataset...\n",
            "‚úÖ Training on 500 examples\n",
            "{'text': '<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is Paracetamol poisoning?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThe answer is: Paracetamol poisoning, also known as acetaminophen poisoning, is caused by excessive use of the medication paracetamol (acetaminophen). Most people have few or non-specific symptoms in the first 24 hours following overdose.<|eot_id|>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj0gd_wharrB",
        "outputId": "390784f5-3550-4ef2-de70-790b59ff3eff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 500\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize"
      ],
      "metadata": {
        "id": "4GICWAmIawiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512,  # Shorter for Mac memory\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "hvfRUc0Jav8c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÑ Tokenizing...\")\n",
        "\n",
        "tokenized_dataset = train_dataset.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=train_dataset.column_names\n",
        ")\n",
        "\n",
        "print(\"Tokenization completed!\")\n",
        "print(tokenized_dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "054304c73b6e41a1973f8ef96fb80777",
            "ba14e70104ec4e71bef6d29d4baa9e25",
            "e5c3bf5de78b4fddb06d4b874680325a",
            "ea027ac70c15425d81eb6ee16bec3478",
            "aec983df602048f9a025372a5f740c86",
            "62ee41d2c2494605aedb5793657d35de",
            "6b659f6fb7904bc4a84f157ec04f2ef0",
            "2ff217fca1f746c7b71ac04012ad58ea",
            "e84464c171154ce4b09c59fa01f46b83",
            "37f2bb8bb5dc4c7d8a43b087b4649549",
            "b5f338cfd0434eddb8b11b0c4cc2fe91"
          ]
        },
        "id": "xayLMN00bQJe",
        "outputId": "ac3c7d8f-e6fe-4026-80ad-d62f3533442c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Tokenizing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "054304c73b6e41a1973f8ef96fb80777"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenization completed!\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 500\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚öôÔ∏è Setting up training...\")\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-4,\n",
        "    warmup_steps=10,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    fp16=False,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiouk6OncyLd",
        "outputId": "52212352-e7f4-4568-9f86-180358acfbc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öôÔ∏è Setting up training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "jO33OKBwc2Gk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                      # your LoRA-wrapped Llama\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,  # from previous step\n",
        "    data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "jn5d4hnDc7SH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüöÄ Starting training...\")\n",
        "print(\"=\"*60)\n",
        "trainer.train()\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gtO0dqH1dIj-",
        "outputId": "168d3025-fa74-48e7-98bd-49428294b047"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting training...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 06:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2.539200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.931300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.856000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.726700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.631800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.529300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.563400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.554700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.590100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.620100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.343100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.514600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.215600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.163200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.130500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.168200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.045700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.066500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.144500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.047300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.172900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>1.101700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.172100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.010000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.198000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.684500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.819300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.774400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.671400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.813500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.728000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.694400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.722300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.779800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.656500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "‚úÖ Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüíæ Saving model...\")\n",
        "\n",
        "save_path = \"./llama3_medical_lora\"\n",
        "\n",
        "# Save LoRA adapters (PEFT model)\n",
        "model.save_pretrained(save_path)\n",
        "\n",
        "# Save tokenizer\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to: {save_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6IHYfdffCg3",
        "outputId": "87af3158-605a-48f4-c7ab-5f62cf39d904"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Saving model...\n",
            "‚úÖ Model saved to: ./llama3_medical_lora\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you are running out of memory run this cell to clear memory\n",
        "import gc\n",
        "\n",
        "# Clear MPS cache\n",
        "if torch.backends.mps.is_available():\n",
        "    torch.mps.empty_cache()\n",
        "\n",
        "# Clear Python garbage collection\n",
        "gc.collect()\n",
        "\n",
        "print(\"‚úÖ Memory cleared!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2OSyG3ki5MK",
        "outputId": "368ffd38-a4e4-409e-b3c4-e91277e4a6ab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Memory cleared!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import time\n",
        "\n",
        "print(\"\\nüìä Loading wiki_medical_terms dataset for evaluation...\")\n",
        "wiki_ds = load_dataset(\"gamino/wiki_medical_terms\")\n",
        "full_dataset = wiki_ds[\"train\"]\n",
        "n_total = len(full_dataset)\n",
        "print(f\"Total examples in wiki_medical_terms: {n_total}\")\n",
        "\n",
        "# On suppose que les 0‚Äì499 ont servi √† l'entra√Ænement\n",
        "test_start = 500\n",
        "test_indices = list(range(test_start, n_total))\n",
        "\n",
        "# On prend 20 exemples al√©atoires dans la zone test\n",
        "num_examples = min(20, len(test_indices))\n",
        "random.seed(42)\n",
        "selected_indices = random.sample(test_indices, num_examples)\n",
        "\n",
        "print(f\"\\nüé≤ Randomly selected {len(selected_indices)} test examples\")\n",
        "print(f\"Indices: {selected_indices[:5]}... (showing first 5)\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# INFERENCE FUNCTION\n",
        "# ============================================================================\n",
        "def get_prediction(question, max_tokens=50):\n",
        "    \"\"\"Generate prediction for a question using the fine-tuned model.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "The answer is:\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            temperature=0.3,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "        )\n",
        "\n",
        "    full_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # On r√©cup√®re juste ce qui suit \"The answer is:\"\n",
        "    if \"The answer is:\" in full_text:\n",
        "        answer = full_text.split(\"The answer is:\", 1)[1].strip()\n",
        "    else:\n",
        "        answer = full_text.strip()\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Small stop-word list for partial-match scoring\n",
        "STOP_WORDS = {\n",
        "    \"the\",\"a\",\"an\",\"of\",\"to\",\"and\",\"or\",\"is\",\"are\",\"in\",\"on\",\"for\",\"with\",\n",
        "    \"by\",\"at\",\"from\",\"this\",\"that\",\"which\",\"what\",\"when\",\"where\",\"why\",\"how\"\n",
        "}\n",
        "\n",
        "def _normalize(text):\n",
        "    \"\"\"lowercase, remove punctuation, split, drop stop-words\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "    tokens = [t for t in text.split() if t and t not in STOP_WORDS]\n",
        "    return tokens\n",
        "\n",
        "# ============================================================================\n",
        "# CHECK ACCURACY\n",
        "# ============================================================================\n",
        "def check_accuracy(prediction, ground_truth):\n",
        "    \"\"\"\n",
        "    Check if prediction is correct.\n",
        "    - Exact match: ground truth appears verbatim (case-insensitive)\n",
        "    - Partial match: ‚â•70% of ground-truth key tokens appear in prediction\n",
        "    \"\"\"\n",
        "\n",
        "    pred_l = prediction.lower()\n",
        "    gt_l = ground_truth.lower()\n",
        "\n",
        "    # 1) Exact match\n",
        "    if gt_l in pred_l:\n",
        "        return True, \"exact_match\"\n",
        "\n",
        "    # 2) Partial match\n",
        "    gt_tokens = _normalize(ground_truth)\n",
        "    if not gt_tokens:\n",
        "        return False, \"no_match\"\n",
        "\n",
        "    pred_tokens = _normalize(prediction)\n",
        "    if not pred_tokens:\n",
        "        return False, \"no_match\"\n",
        "\n",
        "    gt_unique = set(gt_tokens)\n",
        "    common = [t for t in gt_unique if t in pred_tokens]\n",
        "    match_ratio = len(common) / len(gt_unique)\n",
        "\n",
        "    if match_ratio >= 0.7:\n",
        "        return True, \"partial_match\"\n",
        "\n",
        "    return False, \"no_match\"\n",
        "\n",
        "# Initialize variables for evaluation\n",
        "results = []\n",
        "correct_exact = 0\n",
        "correct_partial = 0\n",
        "total = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i, idx in enumerate(selected_indices, 1):\n",
        "    ex = full_dataset[idx]\n",
        "    term = ex[\"page_title\"].strip()\n",
        "    text = ex[\"page_text\"].strip()\n",
        "\n",
        "    # M√™me logique que dans format_prompt\n",
        "    sentences = text.split(\". \")\n",
        "    if len(sentences) == 1:\n",
        "        definition = sentences[0]\n",
        "    else:\n",
        "        definition = \". \".join(sentences[:2])\n",
        "    definition = definition.strip()\n",
        "    if not definition.endswith(\".\"):\n",
        "        definition += \".\"\n",
        "\n",
        "    question = f\"What is {term}?\"\n",
        "    ground_truth = definition\n",
        "\n",
        "    prediction = get_prediction(question)\n",
        "\n",
        "    is_correct, match_type = check_accuracy(prediction, ground_truth)\n",
        "\n",
        "    total += 1\n",
        "    if match_type == \"exact\":\n",
        "        correct_exact += 1\n",
        "    elif match_type == \"partial\":\n",
        "        correct_partial += 1\n",
        "\n",
        "    accuracy = 100.0 * (correct_exact + correct_partial) / total\n",
        "\n",
        "    results.append({\n",
        "        \"index\": idx,\n",
        "        \"question\": question,\n",
        "        \"ground_truth\": ground_truth,\n",
        "        \"prediction\": prediction,\n",
        "        \"correct\": is_correct,\n",
        "        \"match_type\": match_type,\n",
        "    })\n",
        "\n",
        "    print(\"\\n\" + \"-\"*80)\n",
        "    print(f\"Example {i}/{len(selected_indices)} (idx={idx})\")\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"GT: {ground_truth[:120]}...\")\n",
        "    print(f\"Pred: {prediction[:120]}...\")\n",
        "    print(f\"‚úî Correct: {is_correct} ({match_type})\")\n",
        "    print(f\"Running accuracy: {accuracy:.1f}% ({correct_exact + correct_partial}/{total})\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# ============================================================================\n",
        "# FINAL RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "total = len(results)\n",
        "total_correct = correct_exact + correct_partial\n",
        "incorrect = total - total_correct\n",
        "\n",
        "accuracy = 100.0 * total_correct / total if total > 0 else 0.0\n",
        "exact_pct = 100.0 * correct_exact / total if total > 0 else 0.0\n",
        "partial_pct = 100.0 * correct_partial / total if total > 0 else 0.0\n",
        "\n",
        "total_minutes = total_time / 60.0\n",
        "avg_time_sec = total_time / total if total > 0 else 0.0\n",
        "\n",
        "print(f\"\\nTotal examples evaluated: {total}\")\n",
        "print(f\"Exact matches: {correct_exact} ({exact_pct:.1f}%)\")\n",
        "print(f\"Partial matches: {correct_partial} ({partial_pct:.1f}%)\")\n",
        "print(f\"Total correct: {total_correct} ({accuracy:.1f}%)\")\n",
        "print(f\"Incorrect: {incorrect} ({100-accuracy:.1f}%)\\n\")\n",
        "\n",
        "print(f\"Total evaluation time: {total_minutes:.1f} minutes\")\n",
        "print(f\"Average time per example: {avg_time_sec:.1f} seconds\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE ASSESSMENT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if accuracy >= 80:\n",
        "    print(\"üåü EXCELLENT! Model is performing very well!\")\n",
        "    print(\"   Your fine-tuning was highly successful.\")\n",
        "elif accuracy >= 60:\n",
        "    print(\"‚úÖ GOOD! Model learned successfully!\")\n",
        "    print(\"   Consider training longer or with more data for improvement.\")\n",
        "elif accuracy >= 40:\n",
        "    print(\"‚ö†Ô∏è  MODERATE. Model shows some learning.\")\n",
        "    print(\"   Recommend: Train for more epochs or increase dataset size.\")\n",
        "elif accuracy >= 20:\n",
        "    print(\"‚ö†Ô∏è  POOR. Model needs significant improvement.\")\n",
        "    print(\"   Recommend: Check data quality, train longer, or use more examples.\")\n",
        "else:\n",
        "    print(\"‚ùå VERY POOR. Model barely learned.\")\n",
        "    print(\"   Recommend: Verify data formatting and retrain from scratch.\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# SAVE RESULTS\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SAVING RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_summary = {\n",
        "    \"dataset\": \"gamino/wiki_medical_terms\",\n",
        "    \"total_examples\": total,\n",
        "    \"exact_matches\": correct_exact,\n",
        "    \"partial_matches\": correct_partial,\n",
        "    \"incorrect\": incorrect,\n",
        "    \"accuracy\": accuracy,\n",
        "    \"exact_match_pct\": exact_pct,\n",
        "    \"partial_match_pct\": partial_pct,\n",
        "    \"total_time_sec\": total_time,\n",
        "    \"avg_time_sec\": avg_time_sec,\n",
        "    \"selected_indices\": selected_indices,\n",
        "    \"results\": results,\n",
        "}\n",
        "\n",
        "with open('evaluation_results.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to: evaluation_results.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UJWvyCbjGeX",
        "outputId": "c658cb22-44c9-41a3-9204-f6e0d32b4cc6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Loading wiki_medical_terms dataset for evaluation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total examples in wiki_medical_terms: 6861\n",
            "\n",
            "üé≤ Randomly selected 20 test examples\n",
            "Indices: [5738, 1412, 704, 6574, 2753]... (showing first 5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 1/20 (idx=5738)\n",
            "Q: What is Stickler syndrome?\n",
            "GT: Stickler syndrome (hereditary progressive arthro-ophthalmodystrophy) is a group of rare genetic disorders affecting conn...\n",
            "Pred: Stickler syndrome, also known as Stickler disease, is an autosomal recessive inherited disease characterized by problems...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 2/20 (idx=1412)\n",
            "Q: What is Nevus lipomatosus superficialis?\n",
            "GT: Nevus lipomatosus (cutaneous) superficialis (NLS or NLCS, also known as \"Nevus lipomatosis of Hoffman and Zurhelle\") is ...\n",
            "Pred: Nevus lipomatosus superficialis (NLS) is a type of cutaneous nevus that is composed of fat cells. It is a benign conditi...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 3/20 (idx=704)\n",
            "Q: What is Ventricular tachycardia?\n",
            "GT: Ventricular tachycardia (V-tach or VT) is a fast heart rate arising from the lower chambers of the heart. Although a few...\n",
            "Pred: Ventricular tachycardia (V-tach or VT) is a fast heart rate originating in the lower chambers of the heart (the ventricl...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 4/20 (idx=6574)\n",
            "Q: What is Perforation?\n",
            "GT: A perforation is a small hole in a thin material or web. There is usually more than one perforation in an organized fash...\n",
            "Pred: A perforation is a hole made in a wall or lining of a body cavity by a medical instrument. It is a common complication o...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 5/20 (idx=2753)\n",
            "Q: What is Pterygium inversum unguis?\n",
            "GT: Pterygium inversum unguis or ventral pterygium is characterized by the adherence of the distal portion of the nailbed to...\n",
            "Pred: Pterygium inversum unguis (PIU), also known as Pterygium inversum, is a rare, autosomal recessive, genetic disorder that...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 6/20 (idx=2506)\n",
            "Q: What is Gigantism?\n",
            "GT: Gigantism (Greek: Œ≥ŒØŒ≥Œ±œÇ, g√≠gas, \"giant\", plural Œ≥ŒØŒ≥Œ±ŒΩœÑŒµœÇ, g√≠gantes), also known as giantism, is a condition characterize...\n",
            "Pred: Gigantism is a condition of excessive growth that occurs after the bone growth plate has closed. It typically occurs in ...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 7/20 (idx=2328)\n",
            "Q: What is Hypoplastic left heart syndrome?\n",
            "GT: Hypoplastic left heart syndrome (HLHS) is a rare congenital heart defect in which the left side of the heart is severely...\n",
            "Pred: Hypoplastic left heart syndrome (HLHS) is a rare congenital heart defect in which the left side of the heart is underdev...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 8/20 (idx=1643)\n",
            "Q: What is Cystic hygroma?\n",
            "GT: A cystic hygroma is an abnormal growth that usually appears on a babys neck or head. It consists of one or more cysts an...\n",
            "Pred: Cystic hygroma, also known as cystic hygroma syndrome, is a congenital condition in which a fluid-filled sac forms in th...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 9/20 (idx=6533)\n",
            "Q: What is Ocular hypertension?\n",
            "GT: Ocular hypertension is the presence of elevated fluid pressure inside the eye (intraocular pressure), usually with no op...\n",
            "Pred: Ocular hypertension (OHT) is a condition in which the intraocular pressure (IOP) is elevated above the normal range but ...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 10/20 (idx=1339)\n",
            "Q: What is Ovarian remnant syndrome?\n",
            "GT: Ovarian remnant syndrome is a condition that occurs when ovarian tissue is left behind following oophorectomy, causing d...\n",
            "Pred: Ovarian remnant syndrome (ORS) is a condition in which the remaining ovarian tissue after childbirth does not produce en...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 11/20 (idx=6043)\n",
            "Q: What is Anencephaly?\n",
            "GT: Anencephaly is the absence of a major portion of the brain, skull, and scalp that occurs during embryonic development. I...\n",
            "Pred: Anencephaly is a birth defect in which a baby is born without a significant portion of the brain and skull. The brain is...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 12/20 (idx=6567)\n",
            "Q: What is H?\n",
            "GT: H, or h, is the eighth letter in the Latin alphabet, used in the modern English alphabet, the alphabets of other western...\n",
            "Pred: H is the first letter of the chemical symbol for hydrogen. It is the chemical element with atomic number 1, representing...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 13/20 (idx=4967)\n",
            "Q: What is Cancer?\n",
            "GT: Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of th...\n",
            "Pred: Cancer is a group of diseases characterized by uncontrolled cell growth in tissues. Tumors (cancerous growths) can be be...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 14/20 (idx=1212)\n",
            "Q: What is Winchester syndrome?\n",
            "GT: Winchester syndrome is a rare hereditary connective tissue disease described in 1969, of which the main characteristics ...\n",
            "Pred: Winchester syndrome is a rare genetic disease in which a male cat becomes aggressive and destructive. The syndrome is na...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 15/20 (idx=5337)\n",
            "Q: What is Granuloma gluteale infantum?\n",
            "GT: Granuloma gluteale infantum is a cutaneous condition that appears in the anogenital region of infants as a complication ...\n",
            "Pred: Granuloma gluteale infantum (GGA), also known as \"stump\" or \"stump-like\" granuloma gluteale, is a benign, non-cancerous ...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 16/20 (idx=3956)\n",
            "Q: What is Calcipotriol?\n",
            "GT: Calcipotriol, also known as calcipotriene, is a synthetic derivative of calcitriol, a form of vitamin D.  It is used in ...\n",
            "Pred: Calcipotriol, also known as calcipotriene, is a topical medication used to treat psoriasis. It is a synthetic 13-carbon ...\n",
            "‚úî Correct: True (partial_match)\n",
            "Running accuracy: 0.0% (0/16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 17/20 (idx=760)\n",
            "Q: What is Alport syndrome?\n",
            "GT: Alport syndrome is a genetic disorder affecting around 1 in 5,000-10,000 children, characterized by glomerulonephritis, ...\n",
            "Pred: Alport syndrome, also known as hereditary nephritis, is a group of autosomal recessive genetic disorders that affect the...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 18/20 (idx=744)\n",
            "Q: What is Kwashiorkor?\n",
            "GT: Kwashiorkor ( KWOSH-ee-OR-kor, -‚Å†k…ôr, UK also  KWASH-) is a form of severe protein malnutrition characterized by edema a...\n",
            "Pred: Kwashiorkor is a form of malnutrition that occurs when there is not enough protein in the diet, but the body needs more....\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 19/20 (idx=1267)\n",
            "Q: What is Pseudostrabismus?\n",
            "GT: Pseudostrabismus is the false appearance of crossed eyes. When the eyes are actually crossed or not completely aligned w...\n",
            "Pred: Pseudostrabismus, also known as ectopias, is a condition in which the eyes appear to be positioned at different distance...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/19)\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Example 20/20 (idx=2291)\n",
            "Q: What is Capillaritis?\n",
            "GT: Capillaritis is where the capillaries, usually of the legs or lungs, are inflamed, allowing blood cells to pass through....\n",
            "Pred: Capillaritis is a form of inflammation of the capillaries. It is a symptom of various diseases, most commonly rheumatoid...\n",
            "‚úî Correct: False (no_match)\n",
            "Running accuracy: 0.0% (0/20)\n",
            "\n",
            "================================================================================\n",
            "FINAL RESULTS\n",
            "================================================================================\n",
            "\n",
            "Total examples evaluated: 20\n",
            "Exact matches: 0 (0.0%)\n",
            "Partial matches: 0 (0.0%)\n",
            "Total correct: 0 (0.0%)\n",
            "Incorrect: 20 (100.0%)\n",
            "\n",
            "Total evaluation time: 1.4 minutes\n",
            "Average time per example: 4.2 seconds\n",
            "\n",
            "================================================================================\n",
            "PERFORMANCE ASSESSMENT\n",
            "================================================================================\n",
            "‚ùå VERY POOR. Model barely learned.\n",
            "   Recommend: Verify data formatting and retrain from scratch.\n",
            "\n",
            "================================================================================\n",
            "SAVING RESULTS\n",
            "================================================================================\n",
            "‚úÖ Results saved to: evaluation_results.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part A\n",
        "\n",
        "###Q1 ‚Äî Improving Model Performance\n",
        "Augmenter le nombre d‚Äôexemples, entra√Æner plus longtemps (plus d‚Äô√©poques) et utiliser des r√©ponses mieux structur√©es permettrait au mod√®le d‚Äôapprendre des d√©finitions plus coh√©rentes.\n",
        "\n",
        "\n",
        "###Q2 ‚Äî Analyzing Failure Patterns\n",
        "Le mod√®le g√©n√®re des paraphrases proches mais rarement identiques au ground truth, ce qui montre qu‚Äôil s‚Äôappuie surtout sur ses connaissances internes plut√¥t que sur le fine-tuning.\n",
        "\n",
        "\n",
        "###Q3 ‚Äî Data Quality vs Quantity\n",
        "Quelques centaines d‚Äôexemples bien structur√©s auraient plus d‚Äôimpact que de grandes quantit√©s de textes Wikipedia bruts et in√©gaux."
      ],
      "metadata": {
        "id": "ZHMbI52-mZao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part B\n",
        "\n",
        "###Q4 ‚Äî Optimizing for limited resources\n",
        "La quantization (INT8/INT4), des s√©quences plus courtes et LoRA permettent de r√©duire fortement l‚Äôusage m√©moire et le temps d‚Äôinf√©rence.\n",
        "\n",
        "###Q5 ‚Äî Speed vs Accuracy Trade-offs\n",
        "Des param√®tres de g√©n√©ration conservateurs (peu de tokens, temp√©rature basse) am√©liorent la vitesse mais r√©duisent la richesse des r√©ponses."
      ],
      "metadata": {
        "id": "Nygc6WU0mozb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part C\n",
        "\n",
        "###Q7 ‚Äî Improving Evaluation Metrics\n",
        "Une m√©trique s√©mantique (similarit√© d‚Äôembeddings) serait plus adapt√©e que l‚Äôexact/partial match pour comparer des d√©finitions m√©dicales reformul√©es.\n",
        "\n",
        "###Q8 ‚Äî Test Set Size and Confidence\n",
        "√âvaluer sur un √©chantillon plus large (50‚Äì200 exemples) donnerait une mesure de performance beaucoup plus fiable que 20 exemples."
      ],
      "metadata": {
        "id": "tARtnP1imxLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part D\n",
        "###Q9 ‚Äî Production Considerations\n",
        "Une application m√©dicale doit inclure validation humaine, filtres anti-hallucination et un corpus m√©dical v√©rifi√© pour garantir s√©curit√© et fiabilit√©."
      ],
      "metadata": {
        "id": "FIh_hz88m3Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le mod√®le n‚Äôa presque rien appris car le dataset est bruit√©, les r√©ponses longues et le nombre d‚Äôexemples trop faible.\n",
        "Les erreurs sont proches du ground truth mais formul√©es diff√©remment ‚Üí la m√©trique actuelle ne reconna√Æt pas ces proximit√©s.\n",
        "Pour am√©liorer : plus d‚Äôexemples, meilleurs r√©sum√©s, plus d‚Äô√©poques, meilleure m√©trique (similarit√© s√©mantique).\n",
        "Pour l‚Äôinf√©rence limit√©e : LoRA + quantization, r√©duire max_length, prompts plus courts.\n",
        "Pour la production : √©viter les hallucinations, utiliser des datasets m√©dicaux fiables, ajouter validations humaines."
      ],
      "metadata": {
        "id": "c00N7DX9m8we"
      }
    }
  ]
}