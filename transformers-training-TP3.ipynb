{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d96a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Labs/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers torch\n",
    "\n",
    "# Basic imports for the whole lab\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Example text from the lab\n",
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
    "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
    "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
    "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
    "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
    "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
    "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6bf50",
   "metadata": {},
   "source": [
    "### Question 1 – Understanding Pipelines\n",
    "\n",
    "1. A pipeline in Hugging Face is basically a shortcut that handles all the low-level steps for us. It manages the tokenizer, the model, the tensors, and turns raw text into predictions without us worrying about the details. It lets us focus on the task instead of the engineering behind it.\n",
    "\n",
    "2. Transformers offers many different pipeline tasks. For example: question answering, token classification for NER, summarization, translation, text generation, fill-mask, and others.\n",
    "\n",
    "3. If we do not specify a model, the pipeline automatically loads a default one that is recommended for the task. If we want a specific model instead, we just pass its identifier, for example:\n",
    "   classifier = pipeline(text-classification, model=\"distilbert/distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99e4ca",
   "metadata": {},
   "source": [
    "### Question 2 – Text Classification Deep Dive\n",
    "\n",
    "1. The default model used here is distilbert/distilbert-base-uncased-finetuned-sst-2-english.\n",
    "\n",
    "2. This model is fine-tuned on the SST-2 dataset, which contains short movie review sentences labeled as positive or negative. Because of that, it works best on short English sentences where we want to detect sentiment in a simple way.\n",
    "\n",
    "3. The score value is basically the confidence of the model after applying softmax. It is a number between 0 and 1, where values close to 1 mean the model feels quite sure about the prediction.\n",
    "\n",
    "4. A model that predicts emotions instead of only positive or negative is something like j-hartmann/emotion-english-distilroberta-base. These models usually output labels such as joy, anger, sadness, fear, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bcbbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "328628c6-57e1-4a3a-966a-f76f3de5cbfe",
       "rows": [
        [
         "0",
         "NEGATIVE",
         "0.9015459418296814"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.901546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label     score\n",
       "0  NEGATIVE  0.901546"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple sentiment classifier using the default model\n",
    "classifier = pipeline(\"text-classification\")\n",
    "\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c32dee3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "entity_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "2b33db4d-76c9-4233-a19f-7ff21a27d5ae",
       "rows": [
        [
         "0",
         "ORG",
         "0.8790089",
         "Amazon",
         "5",
         "11"
        ],
        [
         "1",
         "MISC",
         "0.9908588",
         "Optimus Prime",
         "36",
         "49"
        ],
        [
         "2",
         "LOC",
         "0.9997547",
         "Germany",
         "90",
         "97"
        ],
        [
         "3",
         "MISC",
         "0.5565669",
         "Mega",
         "208",
         "212"
        ],
        [
         "4",
         "PER",
         "0.59025794",
         "##tron",
         "212",
         "216"
        ],
        [
         "5",
         "ORG",
         "0.6696925",
         "Decept",
         "253",
         "259"
        ],
        [
         "6",
         "MISC",
         "0.49834913",
         "##icons",
         "259",
         "264"
        ],
        [
         "7",
         "MISC",
         "0.7753606",
         "Megatron",
         "350",
         "358"
        ],
        [
         "8",
         "MISC",
         "0.9878539",
         "Optimus Prime",
         "367",
         "380"
        ],
        [
         "9",
         "PER",
         "0.8120963",
         "Bumblebee",
         "502",
         "511"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.879009</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.556567</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.590258</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.669693</td>\n",
       "      <td>Decept</td>\n",
       "      <td>253</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>##icons</td>\n",
       "      <td>259</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.775361</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>350</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>367</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.812096</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>502</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.879009         Amazon      5   11\n",
       "1         MISC  0.990859  Optimus Prime     36   49\n",
       "2          LOC  0.999755        Germany     90   97\n",
       "3         MISC  0.556567           Mega    208  212\n",
       "4          PER  0.590258         ##tron    212  216\n",
       "5          ORG  0.669693         Decept    253  259\n",
       "6         MISC  0.498349        ##icons    259  264\n",
       "7         MISC  0.775361       Megatron    350  358\n",
       "8         MISC  0.987854  Optimus Prime    367  380\n",
       "9          PER  0.812096      Bumblebee    502  511"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition on the complaint text\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "ner_outputs = ner_tagger(text)\n",
    "pd.DataFrame(ner_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbd43737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "entity_group",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "end",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "bda459e6-ebb4-46bd-9aa3-994679426dc7",
       "rows": [
        [
         "0",
         "ORG",
         "0.8790089",
         "Amazon",
         "5",
         "11"
        ],
        [
         "1",
         "MISC",
         "0.9908588",
         "Optimus Prime",
         "36",
         "49"
        ],
        [
         "2",
         "LOC",
         "0.9997547",
         "Germany",
         "90",
         "97"
        ],
        [
         "3",
         "MISC",
         "0.5565669",
         "Mega",
         "208",
         "212"
        ],
        [
         "4",
         "PER",
         "0.59025794",
         "##tron",
         "212",
         "216"
        ],
        [
         "5",
         "ORG",
         "0.6696925",
         "Decept",
         "253",
         "259"
        ],
        [
         "6",
         "MISC",
         "0.49834913",
         "##icons",
         "259",
         "264"
        ],
        [
         "7",
         "MISC",
         "0.7753606",
         "Megatron",
         "350",
         "358"
        ],
        [
         "8",
         "MISC",
         "0.9878539",
         "Optimus Prime",
         "367",
         "380"
        ],
        [
         "9",
         "PER",
         "0.8120963",
         "Bumblebee",
         "502",
         "511"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_group</th>\n",
       "      <th>score</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.879009</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.990859</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOC</td>\n",
       "      <td>0.999755</td>\n",
       "      <td>Germany</td>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.556567</td>\n",
       "      <td>Mega</td>\n",
       "      <td>208</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.590258</td>\n",
       "      <td>##tron</td>\n",
       "      <td>212</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ORG</td>\n",
       "      <td>0.669693</td>\n",
       "      <td>Decept</td>\n",
       "      <td>253</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.498349</td>\n",
       "      <td>##icons</td>\n",
       "      <td>259</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.775361</td>\n",
       "      <td>Megatron</td>\n",
       "      <td>350</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MISC</td>\n",
       "      <td>0.987854</td>\n",
       "      <td>Optimus Prime</td>\n",
       "      <td>367</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PER</td>\n",
       "      <td>0.812096</td>\n",
       "      <td>Bumblebee</td>\n",
       "      <td>502</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  entity_group     score           word  start  end\n",
       "0          ORG  0.879009         Amazon      5   11\n",
       "1         MISC  0.990859  Optimus Prime     36   49\n",
       "2          LOC  0.999755        Germany     90   97\n",
       "3         MISC  0.556567           Mega    208  212\n",
       "4          PER  0.590258         ##tron    212  216\n",
       "5          ORG  0.669693         Decept    253  259\n",
       "6         MISC  0.498349        ##icons    259  264\n",
       "7         MISC  0.775361       Megatron    350  358\n",
       "8         MISC  0.987854  Optimus Prime    367  380\n",
       "9          PER  0.812096      Bumblebee    502  511"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Named Entity Recognition on the complaint text\n",
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "ner_outputs = ner_tagger(text)\n",
    "pd.DataFrame(ner_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387f67d",
   "metadata": {},
   "source": [
    "### Question 3 – Named Entity Recognition\n",
    "\n",
    "1. NER tries to detect important pieces of information in text and assign them to categories. Typical categories are person, organization, location, or miscellaneous entities like product names.\n",
    "\n",
    "2. In our example, the model finds things like Amazon (organization), Optimus Prime and Megatron (misc), Germany (location), and Bumblebee (person). These match the characters and places mentioned in the email.\n",
    "\n",
    "3. The entity_group column is the final entity label. The word column shows the actual text span that was detected. The score is the confidence of the model. The start and end positions are the character indexes of that entity in the original text. Sub-words sometimes appear because of how tokenization works, and the aggregation strategy merges them back into clean entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b867b2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.1923447698354721,\n",
       " 'start': 335,\n",
       " 'end': 358,\n",
       " 'answer': 'an exchange of Megatron'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question Answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "qa_example = qa_pipeline(\n",
    "    question=\"What did the customer receive instead of Optimus Prime?\",\n",
    "    context=text\n",
    ")\n",
    "qa_example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811fc67",
   "metadata": {},
   "source": [
    "### Question 4 – Question Answering Systems\n",
    "\n",
    "1. A question answering system takes two inputs: a question and a context paragraph. The output contains the answer extracted from the context, along with a score and the start and end positions inside the text.\n",
    "\n",
    "2. In our example, the answer always comes directly from the context. The model selects the most likely span that answers the question, instead of inventing a new sentence.\n",
    "\n",
    "3. This method works well when the answer is explicitly written somewhere in the passage. It becomes harder when the answer requires external knowledge, heavy reasoning, or when the context is very long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df52f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Bumblebee ordered an Optimus Prime action figure from your online store in Germany . Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead .'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "summary = summarizer(text, max_length=60, min_length=20, do_sample=False)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b008cf5",
   "metadata": {},
   "source": [
    "### Question 5 – Text Summarization\n",
    "\n",
    "1. The goal of summarization is to compress the original message into a shorter version while keeping the main point. Here, we want a short summary of the complaint email.\n",
    "\n",
    "2. The min_length and max_length parameters control how long the generated summary can be. They limit the number of tokens produced by the model.\n",
    "\n",
    "3. The generated summary keeps the essential idea of the email, even if it skips some details. It usually keeps the main problem and the request from the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7471dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Paul aime la programmation en Python puisqu'il connaît Dallard King\"}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translation pipeline (English to French as an example)\n",
    "\n",
    "# Use T5 as a generic text2text model\n",
    "translator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google-t5/t5-base\"\n",
    ")\n",
    "\n",
    "# T5 expects a task prefix\n",
    "prompt = \"translate English to French: \" + \"Paul loves programming in Python since he knows Dallard King\"\n",
    "\n",
    "translation = translator(\n",
    "    prompt,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "translation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9e861",
   "metadata": {},
   "source": [
    "### Question 6 – Machine Translation\n",
    "\n",
    "1. The translation pipeline rewrites the entire email into another language while keeping the meaning as close as possible. The structure of the message generally remains the same.\n",
    "\n",
    "2. The translation is not always literal. Modern models try to produce natural-sounding sentences in the target language, so some expressions may be slightly rephrased.\n",
    "\n",
    "3. Names like Optimus Prime and Megatron stay unchanged, and sometimes the tone can shift a little, especially in long or formal messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e74eb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Dear Amazon, last week I ordered an Optimus Prime action figure but was told, by a friend, that it would not be available until late November. I was told the only way to get one was through Amazon, but luckily I had a friend who had already purchased one of the figures, and they had a lot of interesting information.\\n\\nThey said, \"All you have to do is grab the figure of your choice from Amazon, and if you want it then come out and buy it. I\\'ve been saying this to Amazon for a couple of years now, and they do want to release a new Optimus Prime figure every few months. I\\'m sure you can find a few of them on Amazon, but most of you won\\'t be able to find one from them. I got a few of them from a friend, but only recently did I get one from Amazon. This time I got it from Amazon with a $0.99 shipping charge. It\\'s been quite a journey to get this one out there, but if you get it, you can thank Amazon for offering you a great deal on a great deal of Transformers toys.\"\\n\\nSo, I\\'m going to be doing my best to explain the situation to you, but here is the thing, I\\'ve used Amazon for a while. It\\'s a little strange that Amazon'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "prompt = \"Dear Amazon, last week I ordered an Optimus Prime action figure but\"\n",
    "generated = generator(\n",
    "    prompt,\n",
    "    max_length=80,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    top_k=50\n",
    ")\n",
    "\n",
    "generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f89bd",
   "metadata": {},
   "source": [
    "### Question 7 – Text Generation\n",
    "\n",
    "1. Text generation is different from the other tasks because the model continues the prompt by creating new text. It is not classifying or extracting information; it is actually producing new sentences.\n",
    "\n",
    "2. max_length sets the maximum number of tokens for the full output. do_sample activates randomness in the generation. top_k means the model only chooses from the top k most likely tokens at each step. These settings change how creative or controlled the output is.\n",
    "\n",
    "3. Simple text generation can sometimes drift off-topic, repeat itself, or produce strange or incorrect statements. There is no guarantee that the produced text is factual, so practical systems usually add constraints or filters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
